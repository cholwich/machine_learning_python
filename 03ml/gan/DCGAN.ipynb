{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvVFoQjdSlMB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(linewidth=500, precision=1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABOBGXte4ibR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52344e7d-465c-4632-dc00-4243eb708e09"
      },
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_train = (x_train - 127.5) / 127.5 # normalize value to [-1, 1]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8YzjWqdVIpN"
      },
      "source": [
        "BUFFER_SIZE = x_train.shape[0]\n",
        "BATCH_SIZE = 2048\n",
        "LATENT_DIM = 100\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQlpexGJVaiO",
        "outputId": "3745114f-a400-4cf9-8c28-0fcf5c32d39f"
      },
      "source": [
        "# Define the discriminator\n",
        "D = tf.keras.Sequential()\n",
        "D.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', \n",
        "                    input_shape=[28, 28, 1]))\n",
        "D.add(layers.LeakyReLU(alpha=0.2))\n",
        "D.add(layers.Dropout(0.3))\n",
        "\n",
        "D.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "D.add(layers.LeakyReLU(alpha=0.2))\n",
        "D.add(layers.Dropout(0.3))\n",
        "\n",
        "D.add(layers.Flatten())\n",
        "D.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Display the discriminator\n",
        "D.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMnnzHwSWlRt",
        "outputId": "11fccd8d-7b0c-482d-b905-4403705b8467"
      },
      "source": [
        "# Define the generator\n",
        "\n",
        "G = tf.keras.Sequential()\n",
        "G.add(layers.Dense(7*7*256, input_shape=(LATENT_DIM, )))\n",
        "G.add(layers.BatchNormalization())\n",
        "G.add(layers.ReLU())\n",
        "\n",
        "G.add(layers.Reshape((7, 7, 256)))\n",
        "\n",
        "G.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same'))\n",
        "G.add(layers.BatchNormalization())\n",
        "G.add(layers.ReLU())\n",
        "\n",
        "G.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "G.add(layers.BatchNormalization())\n",
        "G.add(layers.ReLU())\n",
        "\n",
        "G.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same',\n",
        "                             activation='tanh'))\n",
        "\n",
        "G.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 12544)             1266944   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12544)            50176     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819328    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1601      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,343,681\n",
            "Trainable params: 2,318,209\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "9Wa-ib75bm0k",
        "outputId": "5168e63d-4e68-4a4b-bdf6-15e5507b7072"
      },
      "source": [
        "z = tf.random.normal([1, LATENT_DIM])\n",
        "fake_img = G(z, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa6be215ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiGIHZAtcMBP"
      },
      "source": [
        "# Define losses\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "binary_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(0.9*tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    real_acc = binary_accuracy(tf.ones_like(real_output), real_output)\n",
        "    fake_acc = binary_accuracy(tf.ones_like(fake_output), fake_output)\n",
        "    return (real_loss + fake_loss), (real_acc + fake_acc)/2\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    fake_loss = cross_entropy(0.9*tf.ones_like(fake_output), fake_output)\n",
        "    return fake_loss\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZrwmgzAdDBM"
      },
      "source": [
        "# Define optimizers\n",
        "G_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "D_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cesgHJK-dUV3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as G_tape, tf.GradientTape() as D_tape:\n",
        "        generated_imgs = G(noise, training=True)\n",
        "\n",
        "        real_output = D(images, training=True)\n",
        "        fake_output = D(generated_imgs, training=True)\n",
        "\n",
        "        G_loss = generator_loss(fake_output)\n",
        "        D_loss, D_acc = discriminator_loss(real_output, fake_output)\n",
        "    G_gradients = G_tape.gradient(G_loss, G.trainable_variables)\n",
        "    D_gradients = D_tape.gradient(D_loss, D.trainable_variables)\n",
        "    G_optimizer.apply_gradients(zip(G_gradients, G.trainable_variables))\n",
        "    D_optimizer.apply_gradients(zip(D_gradients, D.trainable_variables))\n",
        "    return G_loss, D_loss, D_acc\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqtl_RUpXogC",
        "outputId": "6e7cc3ae-3258-484c-9ced-0b099d7c1013"
      },
      "source": [
        "EPOCHS = 1000 \n",
        "\n",
        "real = np.ones((BATCH_SIZE, 1))\n",
        "fake = np.zeros((BATCH_SIZE, 1))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    d_loss = g_loss = d_acc = 0.0\n",
        "    n = 0\n",
        "    for batch in dataset:\n",
        "        dl, gl, da = train_step(batch)\n",
        "        d_loss += dl\n",
        "        d_acc += da\n",
        "        g_loss += gl\n",
        "        n += 1\n",
        "    print(\"Epoch %d: d_loss %f, d_acc %f, g_loss %f\" % (epoch+1, d_loss/n, d_acc/n, g_loss/n), end=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: d_loss 0.636836, d_acc 0.943764, g_loss 1.205263\n",
            "Epoch 2: d_loss 0.663691, d_acc 0.952258, g_loss 1.228194\n",
            "Epoch 3: d_loss 0.721298, d_acc 0.836873, g_loss 1.212181\n",
            "Epoch 4: d_loss 0.799039, d_acc 0.765086, g_loss 1.120354\n",
            "Epoch 5: d_loss 1.138447, d_acc 0.709540, g_loss 0.866252\n",
            "Epoch 6: d_loss 1.083287, d_acc 0.667863, g_loss 0.886505\n",
            "Epoch 7: d_loss 1.094151, d_acc 0.634166, g_loss 0.931987\n",
            "Epoch 8: d_loss 1.344186, d_acc 0.607775, g_loss 0.812458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cfc9gGTgeOE"
      },
      "source": [
        "fake_img = G(z, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXe8_z6AtlNo"
      },
      "source": [
        "z1 = tf.random.normal([1, LATENT_DIM])\n",
        "fake_img = G(z1, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTtzGMY_BSR0"
      },
      "source": [
        "z2 = tf.random.normal([1, LATENT_DIM])\n",
        "fake_img = G(z2, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEmMdncMBXwd"
      },
      "source": [
        "z3 = (z1+z2)/2\n",
        "fake_img = G(z3, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KOudTo1Bh1Z"
      },
      "source": [
        "# loaded_model = tf.keras.models.load_model('/content/gdrive/My Drive/dcgan_g')\n",
        "z4 = tf.random.normal([1, LATENT_DIM])\n",
        "fake_img = loaded_model(z4, training=False)\n",
        "plt.imshow(fake_img[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}